\chapter{Introduction}

\begin{quote}
\begin{center}
The most important maxim for data analysis to heed, and one which many\\
statisticians seem to have shunned, is this: "Far better an approximate\\
answer to the right question, which is often vague, than an exact answer\\
to the wrong question, which can always be made precise." \\
---Tukey,(1962)
\end{center}
\end{quote}
There are many choices for how to model data in order to obtain diagnostic information on students' strengths and weaknesses. The choice regarding which model to use may depend on how the learning progression is set up, and can influence the development of the learning progression. In this study, I will use the Earth and Solar System \cite{Briggs2006}, and the Force and Motion \cite {AlonzoSteedle2009} learning progressions in which items are designed to map differences in the LP levels into the options, OMC items. 
As described above, two related but different frameworks are possible for making diagnostic classifications from items to LP levels: IRT and DCM.  For the purpose of this study, the Partial Credit Model \cite{Masters1982} is chosen as an example from an IRT framework, the Attribute Hierarchy Model \cite{GierlLeightonHunka2007} as a pattern recognition model that falls in between a pure IRT and pure DCM approach, and the General Diagnostic Model \cite{vonDavier2008} as a probabilistic model from the DCM framework. 
This research will expand our knowledge in empirically validating learning progressions. I will use three different models to examine whether hypothesized LPs provide a valid and practically useful way of portraying the pathway of student learning and to investigate the quality of assessment items, as well. This research will also provide insight for whether certain decisions made in LP modeling (i.e., from item response theory and diagnostic classification models) result in practically significant differences in inferences. Of particular interest are implications for model choice, such as whether certain models sufficiently provide diagnostic information in connection to learning progressions. Examining the results of empirical analyses by using these different methodologies with the assessments developed through the learning progressions has the potential to provide information which may better serve the purposes of extracting diagnostic information. In addition, differences between the results within different models can help further questioning among those who develop and use learning progressions. 

\section{Research Questions}
The core research question of this dissertation is "when we have assessment items designed for diagnostic purposes, how should we go about modeling responses to them?" More specifically, I pose two specific research questions asnwered in this dissertation.{\em First},what information does each model provide to the researcher about the quality of learning progression hypothesis and assessment items [Q1]? As a subquestion, what information is provided by the PCM model from IRT framework about the quality of LP and assessment items  [Q1A]?. As another subquestion,what information is provided by the AHM and GDM from diagnostic classification models framework about the quality of the learning progressions and assessment items [Q1A]? {\em Second},what are the qualitative differences (student classification) across different models[Q2]? In particular, how similar are the results of analyses for classification of students produced by AHM and GDM from diagnostic framework and PCM from IRT framework [Q12A]? 

